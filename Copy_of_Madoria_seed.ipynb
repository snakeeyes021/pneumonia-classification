{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snakeeyes021/pneumonia-classification/blob/Madoria/Copy_of_Madoria_seed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3756b860"
      },
      "source": [
        "## Madoria "
      ],
      "id": "3756b860"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98fb55ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import PIL\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ],
      "id": "98fb55ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO7MxV-q7qbl",
        "outputId": "3d5d8fcc-035b-465b-9ca5-1412da0c05b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "FO7MxV-q7qbl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdPIs8E9QCo9"
      },
      "outputs": [],
      "source": [
        "# pip install keras-visualizer\n",
        "# !apt-get -qq install -y graphviz && pip install graphviz"
      ],
      "id": "QdPIs8E9QCo9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a80cfd4"
      },
      "source": [
        "Starting off with the content from the seed notebook. "
      ],
      "id": "5a80cfd4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T51WVhr96CNt"
      },
      "outputs": [],
      "source": [
        "train_dir= \"/content/gdrive/MyDrive/chest_xray/train\"\n",
        "test_dir= \"/content/gdrive/MyDrive/chest_xray/test\"\n",
        "val_dir= \"/content/gdrive/MyDrive/chest_xray/val\""
      ],
      "id": "T51WVhr96CNt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "98cdefca",
        "outputId": "a114ab87-f2be-4b88-8ee0-a11eec34f492"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/chest_xray/train/NORMAL'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_norm_dir = os.path.join(train_dir, 'NORMAL')\n",
        "train_pneu_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
        "val_norm_dir = os.path.join(val_dir, 'NORMAL')\n",
        "val_pneu_dir = os.path.join(val_dir, 'PNEUMONIA')\n",
        "test_norm_dir = os.path.join(test_dir, 'NORMAL')\n",
        "test_pneu_dir = os.path.join(test_dir, 'PNEUMONIA')\n",
        "train_norm_dir"
      ],
      "id": "98cdefca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffa745e3",
        "outputId": "b5e0ad18-7658-476b-f0bb-ab4db8265d17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1221"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(train_norm_dir))"
      ],
      "id": "ffa745e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcd1966b",
        "outputId": "0eb8f328-793a-4550-cff7-4f92a782a793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3755"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(train_pneu_dir))"
      ],
      "id": "dcd1966b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59684d90"
      },
      "outputs": [],
      "source": [
        "def image_paths(filepath):\n",
        "    filenames = os.listdir(filepath)\n",
        "    filepaths = [os.path.join(filepath, name) for name in filenames]\n",
        "    return [img for img in filepaths]\n",
        "\n",
        "\n",
        "train_norm_images = image_paths(train_norm_dir)\n",
        "train_pneu_images = image_paths(train_pneu_dir)"
      ],
      "id": "59684d90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ac1fee2"
      },
      "outputs": [],
      "source": [
        "# Normal example\n",
        "PIL.Image.open(train_norm_images[0])"
      ],
      "id": "1ac1fee2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eec8576e",
        "outputId": "f0697f14-10f0-4d31-8d2a-13f69b5a343d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Found 4976 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(rotation_range=30, zoom_range= 0.2, width_shift_range=0.3, \n",
        "                                   height_shift_range=0.3, shear_range= 0.2, rescale=1./255).flow_from_directory(\n",
        "        test_dir, batch_size=624,\n",
        "        target_size=(64, 64)) \n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=30, zoom_range= 0.2, width_shift_range=0.3, \n",
        "                                   height_shift_range=0.3, shear_range= 0.2, rescale=1./255).flow_from_directory(\n",
        "        val_dir, batch_size=256,\n",
        "        target_size=(64, 64))\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=30, zoom_range= 0.2, width_shift_range=0.3, \n",
        "                                   height_shift_range=0.3, shear_range= 0.2, rescale=1./255).flow_from_directory(\n",
        "        train_dir, batch_size=4976,  \n",
        "        target_size=(64, 64))"
      ],
      "id": "eec8576e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3c40388"
      },
      "outputs": [],
      "source": [
        "train_images, train_labels = next(train_generator)\n",
        "test_images, test_labels = next(test_generator)\n",
        "val_images, val_labels = next(val_generator)"
      ],
      "id": "d3c40388"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d73670fc",
        "outputId": "255ff7c4-e780-4c35-e1cf-04bfb7bb228c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4976, 12288)\n",
            "(624, 12288)\n",
            "(256, 12288)\n"
          ]
        }
      ],
      "source": [
        "train_img = train_images.reshape(train_images.shape[0], -1)\n",
        "test_img = test_images.reshape(test_images.shape[0], -1)\n",
        "val_img = val_images.reshape(val_images.shape[0], -1)\n",
        "\n",
        "print(train_img.shape)\n",
        "print(test_img.shape)\n",
        "print(val_img.shape)"
      ],
      "id": "d73670fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5278d0f"
      },
      "outputs": [],
      "source": [
        "train_y = np.reshape(train_labels[:,0], (4976,1))\n",
        "test_y = np.reshape(test_labels[:,0], (624,1))\n",
        "val_y = np.reshape(val_labels[:,0], (256,1))"
      ],
      "id": "f5278d0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce22fbb3"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3)))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "ce22fbb3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8035fb27",
        "outputId": "3db3b4eb-40ca-4c63-e66c-e66b44daa83e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 67s 107ms/step - loss: 0.5054 - acc: 0.7520 - val_loss: 0.8595 - val_acc: 0.5039\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.4530 - acc: 0.7653 - val_loss: 0.7141 - val_acc: 0.6094\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.4002 - acc: 0.8069 - val_loss: 0.5379 - val_acc: 0.7227\n",
            "Epoch 4/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.3338 - acc: 0.8404 - val_loss: 0.4305 - val_acc: 0.7969\n",
            "Epoch 5/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.2917 - acc: 0.8708 - val_loss: 0.4314 - val_acc: 0.8047\n",
            "Epoch 6/50\n",
            "622/622 [==============================] - 35s 55ms/step - loss: 0.2628 - acc: 0.8861 - val_loss: 0.6790 - val_acc: 0.7617\n",
            "Epoch 7/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.2328 - acc: 0.8999 - val_loss: 0.3761 - val_acc: 0.8516\n",
            "Epoch 8/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.1952 - acc: 0.9188 - val_loss: 0.3866 - val_acc: 0.8555\n",
            "Epoch 9/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.1650 - acc: 0.9327 - val_loss: 0.3574 - val_acc: 0.8633\n",
            "Epoch 10/50\n",
            "622/622 [==============================] - 35s 56ms/step - loss: 0.1382 - acc: 0.9415 - val_loss: 0.3816 - val_acc: 0.8750\n",
            "Epoch 11/50\n",
            "622/622 [==============================] - 37s 60ms/step - loss: 0.1159 - acc: 0.9512 - val_loss: 0.3973 - val_acc: 0.8867\n",
            "Epoch 12/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0843 - acc: 0.9691 - val_loss: 0.6056 - val_acc: 0.8555\n",
            "Epoch 13/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0715 - acc: 0.9733 - val_loss: 0.5311 - val_acc: 0.8516\n",
            "Epoch 14/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0748 - acc: 0.9715 - val_loss: 0.4424 - val_acc: 0.8789\n",
            "Epoch 15/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0405 - acc: 0.9849 - val_loss: 0.5823 - val_acc: 0.8477\n",
            "Epoch 16/50\n",
            "622/622 [==============================] - 36s 58ms/step - loss: 0.0357 - acc: 0.9865 - val_loss: 0.5701 - val_acc: 0.8672\n",
            "Epoch 17/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0348 - acc: 0.9869 - val_loss: 0.7965 - val_acc: 0.8633\n",
            "Epoch 18/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 0.0286 - acc: 0.9898 - val_loss: 0.8209 - val_acc: 0.8320\n",
            "Epoch 19/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0195 - acc: 0.9942 - val_loss: 0.6125 - val_acc: 0.8750\n",
            "Epoch 20/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0450 - acc: 0.9857 - val_loss: 0.8768 - val_acc: 0.8281\n",
            "Epoch 21/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 0.0181 - acc: 0.9940 - val_loss: 0.9421 - val_acc: 0.8516\n",
            "Epoch 22/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0253 - acc: 0.9924 - val_loss: 0.8277 - val_acc: 0.8633\n",
            "Epoch 23/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0091 - acc: 0.9976 - val_loss: 1.2252 - val_acc: 0.8359\n",
            "Epoch 24/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 0.0189 - acc: 0.9934 - val_loss: 0.8167 - val_acc: 0.8711\n",
            "Epoch 25/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 0.0300 - acc: 0.9895 - val_loss: 0.8996 - val_acc: 0.8828\n",
            "Epoch 26/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 1.1489 - val_acc: 0.8555\n",
            "Epoch 27/50\n",
            "622/622 [==============================] - 36s 58ms/step - loss: 4.2997e-04 - acc: 1.0000 - val_loss: 1.1641 - val_acc: 0.8672\n",
            "Epoch 28/50\n",
            "622/622 [==============================] - 36s 58ms/step - loss: 2.4913e-04 - acc: 1.0000 - val_loss: 1.2395 - val_acc: 0.8672\n",
            "Epoch 29/50\n",
            "622/622 [==============================] - 37s 60ms/step - loss: 1.6387e-04 - acc: 1.0000 - val_loss: 1.2510 - val_acc: 0.8672\n",
            "Epoch 30/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 1.1082e-04 - acc: 1.0000 - val_loss: 1.3349 - val_acc: 0.8594\n",
            "Epoch 31/50\n",
            "622/622 [==============================] - 38s 62ms/step - loss: 7.8909e-05 - acc: 1.0000 - val_loss: 1.3370 - val_acc: 0.8672\n",
            "Epoch 32/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 5.4425e-05 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.8594\n",
            "Epoch 33/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 4.0097e-05 - acc: 1.0000 - val_loss: 1.4447 - val_acc: 0.8633\n",
            "Epoch 34/50\n",
            "622/622 [==============================] - 38s 62ms/step - loss: 2.7424e-05 - acc: 1.0000 - val_loss: 1.5004 - val_acc: 0.8594\n",
            "Epoch 35/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 1.9112e-05 - acc: 1.0000 - val_loss: 1.5574 - val_acc: 0.8594\n",
            "Epoch 36/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 1.3803e-05 - acc: 1.0000 - val_loss: 1.6270 - val_acc: 0.8516\n",
            "Epoch 37/50\n",
            "622/622 [==============================] - 37s 60ms/step - loss: 9.9175e-06 - acc: 1.0000 - val_loss: 1.6844 - val_acc: 0.8555\n",
            "Epoch 38/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 6.8136e-06 - acc: 1.0000 - val_loss: 1.7451 - val_acc: 0.8555\n",
            "Epoch 39/50\n",
            "622/622 [==============================] - 35s 57ms/step - loss: 4.9494e-06 - acc: 1.0000 - val_loss: 1.7257 - val_acc: 0.8633\n",
            "Epoch 40/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 3.4320e-06 - acc: 1.0000 - val_loss: 1.8197 - val_acc: 0.8594\n",
            "Epoch 41/50\n",
            "622/622 [==============================] - 36s 57ms/step - loss: 2.5347e-06 - acc: 1.0000 - val_loss: 1.8820 - val_acc: 0.8594\n",
            "Epoch 42/50\n",
            "622/622 [==============================] - 36s 58ms/step - loss: 1.6891e-06 - acc: 1.0000 - val_loss: 1.9290 - val_acc: 0.8594\n",
            "Epoch 43/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 1.2263e-06 - acc: 1.0000 - val_loss: 1.9858 - val_acc: 0.8594\n",
            "Epoch 44/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 8.6302e-07 - acc: 1.0000 - val_loss: 2.0656 - val_acc: 0.8594\n",
            "Epoch 45/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 6.0012e-07 - acc: 1.0000 - val_loss: 2.0716 - val_acc: 0.8594\n",
            "Epoch 46/50\n",
            "622/622 [==============================] - 38s 62ms/step - loss: 4.1327e-07 - acc: 1.0000 - val_loss: 2.1576 - val_acc: 0.8594\n",
            "Epoch 47/50\n",
            "622/622 [==============================] - 38s 61ms/step - loss: 2.9770e-07 - acc: 1.0000 - val_loss: 2.1563 - val_acc: 0.8633\n",
            "Epoch 48/50\n",
            "622/622 [==============================] - 39s 62ms/step - loss: 2.1634e-07 - acc: 1.0000 - val_loss: 2.2753 - val_acc: 0.8594\n",
            "Epoch 49/50\n",
            "622/622 [==============================] - 38s 62ms/step - loss: 1.5040e-07 - acc: 1.0000 - val_loss: 2.3711 - val_acc: 0.8516\n",
            "Epoch 50/50\n",
            "622/622 [==============================] - 39s 62ms/step - loss: 1.0947e-07 - acc: 1.0000 - val_loss: 2.3502 - val_acc: 0.8594\n",
            "156/156 [==============================] - 8s 53ms/step - loss: 7.8083e-08 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 4.3710 - acc: 0.7997\n",
            "This is the training result: [7.808342417092717e-08, 1.0]\n",
            "This is the test results: [4.370972633361816, 0.7996794581413269]\n"
          ]
        }
      ],
      "source": [
        "batch = 8\n",
        "\n",
        "history = model.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch, verbose= 1,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model.evaluate(train_images, train_y)\n",
        "results_test = model.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "8035fb27"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dir375O-cK2N"
      },
      "outputs": [],
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3), kernel_regularizer=regularizers.l2(0.005)))\n",
        "model2.add(layers.Dropout(0.3))\n",
        "\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(layers.Conv2D(32, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model2.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "Dir375O-cK2N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db90b78e",
        "outputId": "d046b091-0d86-448f-83b1-aa5daf83aac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.6134 - acc: 0.7546 - val_loss: 0.7775 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5509 - acc: 0.7546 - val_loss: 0.8206 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5189 - acc: 0.7546 - val_loss: 0.8343 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "622/622 [==============================] - 44s 71ms/step - loss: 0.5111 - acc: 0.7546 - val_loss: 0.7234 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "622/622 [==============================] - 44s 71ms/step - loss: 0.5075 - acc: 0.7546 - val_loss: 0.7429 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "622/622 [==============================] - 44s 70ms/step - loss: 0.5048 - acc: 0.7546 - val_loss: 0.7958 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.5054 - acc: 0.7546 - val_loss: 0.7607 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5047 - acc: 0.7546 - val_loss: 0.8271 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.5033 - acc: 0.7546 - val_loss: 0.7601 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5038 - acc: 0.7546 - val_loss: 0.7385 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5029 - acc: 0.7546 - val_loss: 0.7844 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5037 - acc: 0.7546 - val_loss: 0.7809 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5029 - acc: 0.7546 - val_loss: 0.7570 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5026 - acc: 0.7546 - val_loss: 0.7304 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5034 - acc: 0.7546 - val_loss: 0.7655 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5021 - acc: 0.7546 - val_loss: 0.7790 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5028 - acc: 0.7546 - val_loss: 0.7475 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5016 - acc: 0.7546 - val_loss: 0.7323 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5025 - acc: 0.7546 - val_loss: 0.7476 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5020 - acc: 0.7546 - val_loss: 0.7297 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5018 - acc: 0.7546 - val_loss: 0.7460 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.5018 - acc: 0.7546 - val_loss: 0.7788 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5020 - acc: 0.7546 - val_loss: 0.8366 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.5015 - acc: 0.7546 - val_loss: 0.7635 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5013 - acc: 0.7546 - val_loss: 0.8069 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.5016 - acc: 0.7546 - val_loss: 0.7846 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4997 - acc: 0.7546 - val_loss: 0.8852 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5010 - acc: 0.7546 - val_loss: 0.7692 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.5009 - acc: 0.7546 - val_loss: 0.7791 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5003 - acc: 0.7546 - val_loss: 0.8183 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5005 - acc: 0.7546 - val_loss: 0.7762 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4991 - acc: 0.7546 - val_loss: 0.8054 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5006 - acc: 0.7546 - val_loss: 0.7494 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.4984 - acc: 0.7546 - val_loss: 0.7313 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.4984 - acc: 0.7546 - val_loss: 0.8374 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4994 - acc: 0.7546 - val_loss: 0.7954 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4992 - acc: 0.7546 - val_loss: 0.7919 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4981 - acc: 0.7546 - val_loss: 0.7676 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4974 - acc: 0.7546 - val_loss: 0.8294 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4977 - acc: 0.7546 - val_loss: 0.7616 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4979 - acc: 0.7546 - val_loss: 0.7759 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4969 - acc: 0.7546 - val_loss: 0.7638 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4972 - acc: 0.7546 - val_loss: 0.7533 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4974 - acc: 0.7546 - val_loss: 0.7850 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.4964 - acc: 0.7546 - val_loss: 0.7971 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4966 - acc: 0.7546 - val_loss: 0.8083 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4965 - acc: 0.7546 - val_loss: 0.7382 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4975 - acc: 0.7546 - val_loss: 0.8175 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.4962 - acc: 0.7546 - val_loss: 0.7898 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4967 - acc: 0.7546 - val_loss: 0.8004 - val_acc: 0.5000\n",
            "156/156 [==============================] - 9s 55ms/step - loss: 0.5033 - acc: 0.7546\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.7504 - acc: 0.6250\n",
            "This is the training result: [0.5032855272293091, 0.7546221613883972]\n",
            "This is the test results: [0.7504091262817383, 0.625]\n"
          ]
        }
      ],
      "source": [
        "history = model2.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch, verbose=1,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model2.evaluate(train_images, train_y)\n",
        "results_test = model2.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "db90b78e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQg3TtJHyOH2",
        "outputId": "1ed36b71-151e-4b55-c251-6bd42117fb3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight for class 0: 2.04\n",
            "Weight for class 1: 0.66\n"
          ]
        }
      ],
      "source": [
        "normal= len(os.listdir(train_norm_dir))\n",
        "pneumonia= len(os.listdir(train_pneu_dir))\n",
        "\n",
        "train_count = normal + pneumonia\n",
        "weight_for_0 = (1 / normal) * (train_count) / 2.0\n",
        "weight_for_1 = (1 / pneumonia) * (train_count) / 2.0\n",
        "\n",
        "weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print(\"Weight for class 0: {:.2f}\".format(weight_for_0))\n",
        "print(\"Weight for class 1: {:.2f}\".format(weight_for_1))"
      ],
      "id": "fQg3TtJHyOH2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27fac4c2"
      },
      "outputs": [],
      "source": [
        "model3 = models.Sequential()\n",
        "model3.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3), kernel_regularizer=regularizers.l2(0.005)))\n",
        "model3.add(layers.Dropout(0.3))\n",
        "\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Conv2D(32, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Flatten())\n",
        "model3.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
        "model3.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "model3.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "27fac4c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuqRzTDIoruq",
        "outputId": "2ca22c6f-3d3c-4e47-8c0e-6e9b7e95a588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5337 - acc: 0.7546 - val_loss: 1.1824 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5224 - acc: 0.7546 - val_loss: 1.1586 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.5190 - acc: 0.7546 - val_loss: 1.0781 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.5124 - acc: 0.7546 - val_loss: 1.4135 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5155 - acc: 0.7546 - val_loss: 1.2127 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "622/622 [==============================] - 50s 80ms/step - loss: 0.5111 - acc: 0.7546 - val_loss: 1.3484 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.5089 - acc: 0.7546 - val_loss: 1.0778 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.5093 - acc: 0.7546 - val_loss: 1.1150 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.5065 - acc: 0.7546 - val_loss: 1.2258 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "622/622 [==============================] - 50s 81ms/step - loss: 0.5062 - acc: 0.7546 - val_loss: 1.1938 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5061 - acc: 0.7546 - val_loss: 1.1410 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "622/622 [==============================] - 48s 78ms/step - loss: 0.5050 - acc: 0.7546 - val_loss: 1.0749 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.5055 - acc: 0.7546 - val_loss: 1.1064 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.5040 - acc: 0.7546 - val_loss: 1.0957 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.5039 - acc: 0.7546 - val_loss: 1.2189 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.5021 - acc: 0.7546 - val_loss: 1.2735 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.5016 - acc: 0.7546 - val_loss: 1.1437 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.5029 - acc: 0.7546 - val_loss: 0.9869 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.5016 - acc: 0.7546 - val_loss: 1.2404 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.5017 - acc: 0.7546 - val_loss: 1.3466 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.5001 - acc: 0.7546 - val_loss: 1.1670 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.4992 - acc: 0.7546 - val_loss: 1.1073 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.4997 - acc: 0.7546 - val_loss: 1.0159 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4993 - acc: 0.7546 - val_loss: 1.1303 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4993 - acc: 0.7546 - val_loss: 1.1557 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4986 - acc: 0.7546 - val_loss: 1.2538 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4973 - acc: 0.7546 - val_loss: 1.2343 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4976 - acc: 0.7546 - val_loss: 1.2133 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4980 - acc: 0.7546 - val_loss: 1.1970 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4972 - acc: 0.7546 - val_loss: 1.1980 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.4972 - acc: 0.7546 - val_loss: 1.1075 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4968 - acc: 0.7546 - val_loss: 1.1354 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4971 - acc: 0.7546 - val_loss: 1.1272 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4975 - acc: 0.7546 - val_loss: 1.1511 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.4963 - acc: 0.7546 - val_loss: 1.1933 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.4963 - acc: 0.7546 - val_loss: 1.2077 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.4963 - acc: 0.7546 - val_loss: 1.1629 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4953 - acc: 0.7546 - val_loss: 1.0693 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4963 - acc: 0.7546 - val_loss: 1.1297 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4966 - acc: 0.7546 - val_loss: 1.1361 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4956 - acc: 0.7546 - val_loss: 1.1479 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4956 - acc: 0.7546 - val_loss: 1.1885 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.4955 - acc: 0.7546 - val_loss: 1.1084 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.4955 - acc: 0.7546 - val_loss: 1.0763 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.4946 - acc: 0.7546 - val_loss: 1.1663 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.4947 - acc: 0.7546 - val_loss: 1.2055 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.4949 - acc: 0.7546 - val_loss: 1.2263 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "622/622 [==============================] - 48s 76ms/step - loss: 0.4945 - acc: 0.7546 - val_loss: 1.1315 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.4949 - acc: 0.7546 - val_loss: 1.0950 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.4942 - acc: 0.7546 - val_loss: 1.2553 - val_acc: 0.5000\n",
            "156/156 [==============================] - 9s 57ms/step - loss: 0.6624 - acc: 0.7546\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.0612 - acc: 0.6250\n",
            "This is the training result: [0.6624153256416321, 0.7546221613883972]\n",
            "This is the test results: [1.061238169670105, 0.625]\n"
          ]
        }
      ],
      "source": [
        "history = model3.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch, verbose=1, class_weight=weight,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model3.evaluate(train_images, train_y)\n",
        "results_test = model3.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "ZuqRzTDIoruq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STCROdsnz6H4"
      },
      "outputs": [],
      "source": [
        "model4 = models.Sequential()\n",
        "model4.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3)))\n",
        "model4.add(layers.Dropout(0.3))\n",
        "\n",
        "model4.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model4.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
        "model4.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model4.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model4.add(layers.Flatten())\n",
        "model4.add(layers.Dense(64, activation='relu'))\n",
        "model4.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model4.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "STCROdsnz6H4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9795HIw0JkH",
        "outputId": "f2484b97-7165-48f3-f076-2d95803f4d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 47s 74ms/step - loss: 0.5277 - acc: 0.7536 - val_loss: 1.0461 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4573 - acc: 0.7556 - val_loss: 1.0442 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.4230 - acc: 0.7615 - val_loss: 1.0349 - val_acc: 0.5195\n",
            "Epoch 4/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.3594 - acc: 0.7994 - val_loss: 0.7049 - val_acc: 0.6445\n",
            "Epoch 5/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.3209 - acc: 0.8338 - val_loss: 0.6247 - val_acc: 0.6758\n",
            "Epoch 6/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.2915 - acc: 0.8547 - val_loss: 0.6818 - val_acc: 0.6914\n",
            "Epoch 7/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.2594 - acc: 0.8768 - val_loss: 0.6654 - val_acc: 0.6992\n",
            "Epoch 8/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.2248 - acc: 0.8987 - val_loss: 0.5968 - val_acc: 0.7383\n",
            "Epoch 9/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.1970 - acc: 0.9134 - val_loss: 0.7836 - val_acc: 0.7227\n",
            "Epoch 10/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.1590 - acc: 0.9341 - val_loss: 0.7246 - val_acc: 0.7305\n",
            "Epoch 11/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.1261 - acc: 0.9451 - val_loss: 1.0038 - val_acc: 0.7070\n",
            "Epoch 12/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0998 - acc: 0.9594 - val_loss: 1.4367 - val_acc: 0.6680\n",
            "Epoch 13/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0951 - acc: 0.9600 - val_loss: 0.5399 - val_acc: 0.8125\n",
            "Epoch 14/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0668 - acc: 0.9753 - val_loss: 0.8187 - val_acc: 0.7539\n",
            "Epoch 15/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0558 - acc: 0.9771 - val_loss: 1.7263 - val_acc: 0.6719\n",
            "Epoch 16/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.0493 - acc: 0.9793 - val_loss: 0.6080 - val_acc: 0.8477\n",
            "Epoch 17/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0332 - acc: 0.9883 - val_loss: 1.1626 - val_acc: 0.7734\n",
            "Epoch 18/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.0680 - acc: 0.9757 - val_loss: 0.9599 - val_acc: 0.7891\n",
            "Epoch 19/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0179 - acc: 0.9922 - val_loss: 1.2122 - val_acc: 0.8164\n",
            "Epoch 20/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0294 - acc: 0.9881 - val_loss: 0.9106 - val_acc: 0.8086\n",
            "Epoch 21/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0245 - acc: 0.9908 - val_loss: 1.0449 - val_acc: 0.8203\n",
            "Epoch 22/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0249 - acc: 0.9912 - val_loss: 1.5218 - val_acc: 0.7383\n",
            "Epoch 23/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.0488 - acc: 0.9833 - val_loss: 0.9662 - val_acc: 0.8008\n",
            "Epoch 24/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0201 - acc: 0.9934 - val_loss: 1.2242 - val_acc: 0.7695\n",
            "Epoch 25/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0226 - acc: 0.9922 - val_loss: 1.3172 - val_acc: 0.8008\n",
            "Epoch 26/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.0174 - acc: 0.9952 - val_loss: 1.1945 - val_acc: 0.7969\n",
            "Epoch 27/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.0361 - acc: 0.9922 - val_loss: 0.9287 - val_acc: 0.7812\n",
            "Epoch 28/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.0209 - acc: 0.9924 - val_loss: 1.6982 - val_acc: 0.7656\n",
            "Epoch 29/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.0362 - acc: 0.9855 - val_loss: 1.5932 - val_acc: 0.7773\n",
            "Epoch 30/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 1.3489 - val_acc: 0.7891\n",
            "Epoch 31/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 1.2265 - val_acc: 0.8320\n",
            "Epoch 32/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 9.6575e-04 - acc: 0.9998 - val_loss: 1.1995 - val_acc: 0.8164\n",
            "Epoch 33/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 3.4083e-04 - acc: 1.0000 - val_loss: 1.4874 - val_acc: 0.8242\n",
            "Epoch 34/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 3.3477e-04 - acc: 1.0000 - val_loss: 1.4008 - val_acc: 0.8242\n",
            "Epoch 35/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 9.1527e-05 - acc: 1.0000 - val_loss: 1.4774 - val_acc: 0.8281\n",
            "Epoch 36/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 7.3402e-05 - acc: 1.0000 - val_loss: 1.4821 - val_acc: 0.8398\n",
            "Epoch 37/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 6.0165e-05 - acc: 1.0000 - val_loss: 1.5432 - val_acc: 0.8359\n",
            "Epoch 38/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 3.7860e-05 - acc: 1.0000 - val_loss: 1.4543 - val_acc: 0.8359\n",
            "Epoch 39/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.0764 - acc: 0.9775 - val_loss: 1.7225 - val_acc: 0.7188\n",
            "Epoch 40/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0372 - acc: 0.9839 - val_loss: 1.0384 - val_acc: 0.8281\n",
            "Epoch 41/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 1.3086 - val_acc: 0.8047\n",
            "Epoch 42/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 1.4818 - val_acc: 0.7891\n",
            "Epoch 43/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 7.7058e-04 - acc: 1.0000 - val_loss: 1.5258 - val_acc: 0.8086\n",
            "Epoch 44/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.0394 - acc: 0.9875 - val_loss: 1.0893 - val_acc: 0.8047\n",
            "Epoch 45/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.0111 - acc: 0.9962 - val_loss: 1.3795 - val_acc: 0.7930\n",
            "Epoch 46/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.0263 - acc: 0.9916 - val_loss: 1.2210 - val_acc: 0.8125\n",
            "Epoch 47/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 1.3560 - val_acc: 0.8047\n",
            "Epoch 48/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.0275 - acc: 0.9918 - val_loss: 1.3105 - val_acc: 0.7969\n",
            "Epoch 49/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.0133 - acc: 0.9964 - val_loss: 1.5468 - val_acc: 0.7930\n",
            "Epoch 50/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.0153 - acc: 0.9954 - val_loss: 1.3203 - val_acc: 0.7852\n",
            "156/156 [==============================] - 9s 56ms/step - loss: 0.0315 - acc: 0.9918\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 2.7691 - acc: 0.7388\n",
            "This is the training result: [0.03152099996805191, 0.9917604327201843]\n",
            "This is the test results: [2.7690773010253906, 0.7387820482254028]\n"
          ]
        }
      ],
      "source": [
        "history = model4.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50, class_weight=weight,\n",
        "                    batch_size=batch, verbose=1,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model4.evaluate(train_images, train_y)\n",
        "results_test = model4.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "d9795HIw0JkH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58xAw-94U0TT"
      },
      "outputs": [],
      "source": [
        "model5 = models.Sequential()\n",
        "model5.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3), kernel_regularizer=regularizers.l1(0.005)))\n",
        "model5.add(layers.Dropout(0.3))\n",
        "\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model5.add(layers.Conv2D(32, (4, 4), activation='relu', kernel_regularizer=regularizers.l1(0.005)))\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model5.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l1(0.005)))\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model5.add(layers.Flatten())\n",
        "model5.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.005)))\n",
        "model5.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l1(0.005)))\n",
        "\n",
        "model5.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "58xAw-94U0TT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjd9tN0tU8wo",
        "outputId": "3ad125ce-ae4a-482f-c202-85315589588d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 49s 77ms/step - loss: 1.8217 - acc: 0.7530 - val_loss: 0.9938 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.7093 - acc: 0.7546 - val_loss: 0.9178 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 52s 83ms/step - loss: 0.6945 - acc: 0.7546 - val_loss: 0.9604 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "622/622 [==============================] - 53s 85ms/step - loss: 0.6882 - acc: 0.7546 - val_loss: 0.9173 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "622/622 [==============================] - 49s 78ms/step - loss: 0.6808 - acc: 0.7546 - val_loss: 0.9541 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "622/622 [==============================] - 49s 78ms/step - loss: 0.6752 - acc: 0.7546 - val_loss: 0.9447 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "622/622 [==============================] - 49s 78ms/step - loss: 0.6736 - acc: 0.7546 - val_loss: 0.9560 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "622/622 [==============================] - 53s 86ms/step - loss: 0.6724 - acc: 0.7546 - val_loss: 0.9523 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6714 - acc: 0.7546 - val_loss: 0.9673 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6721 - acc: 0.7546 - val_loss: 0.9509 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.6711 - acc: 0.7546 - val_loss: 0.9416 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.6702 - acc: 0.7546 - val_loss: 0.9547 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.6697 - acc: 0.7546 - val_loss: 0.9485 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6690 - acc: 0.7546 - val_loss: 0.9616 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6686 - acc: 0.7546 - val_loss: 0.9688 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.6687 - acc: 0.7546 - val_loss: 0.9626 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.6683 - acc: 0.7546 - val_loss: 0.9457 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6682 - acc: 0.7546 - val_loss: 0.9426 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.6682 - acc: 0.7546 - val_loss: 0.9486 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6681 - acc: 0.7546 - val_loss: 0.9439 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.6673 - acc: 0.7546 - val_loss: 0.9400 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "622/622 [==============================] - 50s 81ms/step - loss: 0.6671 - acc: 0.7546 - val_loss: 0.9525 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.6672 - acc: 0.7546 - val_loss: 0.9488 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "622/622 [==============================] - 46s 75ms/step - loss: 0.6669 - acc: 0.7546 - val_loss: 0.9412 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6667 - acc: 0.7546 - val_loss: 0.9494 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6665 - acc: 0.7546 - val_loss: 0.9465 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6665 - acc: 0.7546 - val_loss: 0.9481 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6664 - acc: 0.7546 - val_loss: 0.9447 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6662 - acc: 0.7546 - val_loss: 0.9475 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "622/622 [==============================] - 50s 81ms/step - loss: 0.6661 - acc: 0.7546 - val_loss: 0.9559 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.6660 - acc: 0.7546 - val_loss: 0.9471 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.6659 - acc: 0.7546 - val_loss: 0.9469 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.6658 - acc: 0.7546 - val_loss: 0.9489 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6657 - acc: 0.7546 - val_loss: 0.9481 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6657 - acc: 0.7546 - val_loss: 0.9483 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6654 - acc: 0.7546 - val_loss: 0.9459 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "622/622 [==============================] - 47s 76ms/step - loss: 0.6654 - acc: 0.7546 - val_loss: 0.9538 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6652 - acc: 0.7546 - val_loss: 0.9378 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6653 - acc: 0.7546 - val_loss: 0.9492 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6652 - acc: 0.7546 - val_loss: 0.9471 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "622/622 [==============================] - 45s 72ms/step - loss: 0.6651 - acc: 0.7546 - val_loss: 0.9502 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6651 - acc: 0.7546 - val_loss: 0.9447 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6650 - acc: 0.7546 - val_loss: 0.9517 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6649 - acc: 0.7546 - val_loss: 0.9538 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "622/622 [==============================] - 45s 73ms/step - loss: 0.6650 - acc: 0.7546 - val_loss: 0.9469 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.6649 - acc: 0.7546 - val_loss: 0.9471 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "622/622 [==============================] - 46s 74ms/step - loss: 0.6647 - acc: 0.7546 - val_loss: 0.9527 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "622/622 [==============================] - 46s 73ms/step - loss: 0.6647 - acc: 0.7546 - val_loss: 0.9512 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6647 - acc: 0.7546 - val_loss: 0.9502 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "622/622 [==============================] - 47s 75ms/step - loss: 0.6646 - acc: 0.7546 - val_loss: 0.9477 - val_acc: 0.5000\n",
            "156/156 [==============================] - 8s 53ms/step - loss: 0.6641 - acc: 0.7546\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.8085 - acc: 0.6250\n",
            "This is the training result: [0.6640607118606567, 0.7546221613883972]\n",
            "This is the test results: [0.8084681630134583, 0.625]\n"
          ]
        }
      ],
      "source": [
        "history = model5.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch, verbose=1,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model5.evaluate(train_images, train_y)\n",
        "results_test = model5.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "Kjd9tN0tU8wo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2c59T7PCcac"
      },
      "outputs": [],
      "source": [
        "model6 = models.Sequential()\n",
        "model6.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64 ,64,  3), kernel_regularizer=regularizers.l2(0.05)))\n",
        "model6.add(layers.Dropout(0.3))\n",
        "\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model6.add(layers.Conv2D(32, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(0.05)))\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model6.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.05)))\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\n",
        "model6.add(layers.Dropout(0.3))\n",
        "\n",
        "model6.add(layers.Flatten())\n",
        "model6.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.05)))\n",
        "model6.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.05)))\n",
        "\n",
        "model6.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['acc'])"
      ],
      "id": "c2c59T7PCcac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NMruJ7ACkkF",
        "outputId": "74b67968-4378-4e02-a8ea-8ef5983593b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "622/622 [==============================] - 49s 77ms/step - loss: 1.8217 - acc: 0.7530 - val_loss: 0.9938 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "622/622 [==============================] - 48s 77ms/step - loss: 0.7093 - acc: 0.7546 - val_loss: 0.9178 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "622/622 [==============================] - 52s 83ms/step - loss: 0.6945 - acc: 0.7546 - val_loss: 0.9604 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "185/622 [=======>......................] - ETA: 41s - loss: 0.6680 - acc: 0.7764"
          ]
        }
      ],
      "source": [
        "history = model6.fit(train_images,\n",
        "                    train_y,\n",
        "                    epochs=50, class_weight=weight,\n",
        "                    batch_size=batch, verbose=1,\n",
        "                    validation_data=(val_images, val_y))\n",
        "\n",
        "results_train = model5.evaluate(train_images, train_y)\n",
        "results_test = model5.evaluate(test_images, test_y)\n",
        "\n",
        "print(f'This is the training result: {results_train}')\n",
        "print(f'This is the test results: {results_test}')"
      ],
      "id": "0NMruJ7ACkkF"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Madoria-seed.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "d2f5a53b1e33a43d9b2d948d9a196b70d8d8637641a555647cecaa854bbb4499"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('learn-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}